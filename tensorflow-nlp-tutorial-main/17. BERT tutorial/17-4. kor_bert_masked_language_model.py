# -*- coding: utf-8 -*-
"""KLUE BERT를 이용한 마스크드 언어 모델ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iigCAqCh89tsJj35_ps1-zKNwhXPe2x1

링크 : https://wikidocs.net/152922

# 한국어 BERT
"""

!pip install transformers

import transformers
transformers.__version__

from transformers import TFBertForMaskedLM

model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")

inputs = tokenizer('축구는 정말 재미있는 [MASK]다.', return_tensors='tf')

tokenizer.cls_token_id

tokenizer.sep_token_id

tokenizer.mask_token_id

print(inputs['input_ids'])

print(inputs['token_type_ids'])

print(inputs['attention_mask'])

from transformers import FillMaskPipeline
pip = FillMaskPipeline(model=model, tokenizer=tokenizer)

pip('축구는 정말 재미있는 [MASK]다.')

pip('어벤져스는 정말 재미있는 [MASK]다.')

pip('나는 오늘 아침에 [MASK]에 출근을 했다.')