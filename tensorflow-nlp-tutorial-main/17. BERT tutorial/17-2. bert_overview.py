# -*- coding: utf-8 -*-
"""BERT overview.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16KawqsLMb_fECUi_wUMT_5dA3LsfRIi2
"""

pip install transformers

import pandas as pd
from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased") # Bert-base의 토크나이저

result = tokenizer.tokenize('Here is the sentence I want embeddings for.')
print(result)

print(tokenizer.vocab['here'])

print(tokenizer.vocab['embeddings'])

print(tokenizer.vocab['em'])

print(tokenizer.vocab['##bed'])

print(tokenizer.vocab['##ding'])

print(tokenizer.vocab['##s'])

# BERT의 단어 집합을 vocabulary.txt에 저장
with open('vocabulary.txt', 'w') as f:
  for token in tokenizer.vocab.keys():
    f.write(token + '\n')

df = pd.read_fwf('vocabulary.txt', header=None)
df

print('단어 집합의 크기 :',len(df))

df.loc[4667].values[0]

df.loc[102].values[0]