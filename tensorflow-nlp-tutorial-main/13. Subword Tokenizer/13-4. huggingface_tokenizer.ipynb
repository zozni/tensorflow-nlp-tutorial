{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Wordpiece Tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "이 자료는 위키독스 딥 러닝을 이용한 자연어 처리 입문의 허깅페이스 토크나이저 학습 자료입니다.  \n",
        "\n",
        "링크 : https://wikidocs.net/99893"
      ],
      "metadata": {
        "id": "T8_43unDo-sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. BERT의 워드피스 토크나이저(BertWordPieceTokenizer)"
      ],
      "metadata": {
        "id": "HM5ahbJ5pHYp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuyGviaGpdTC",
        "outputId": "85c6e8e0-dde4-4740-ad34-d143916c486e"
      },
      "source": [
        "pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I6y5vrE1qyH-",
        "outputId": "f52ea60c-1df1-43bf-eade-277a90745eb9"
      },
      "source": [
        "import tokenizers\n",
        "tokenizers.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.10.3'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjIo8gG7pir-"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "from tokenizers import BertWordPieceTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy6bJkk-qEqG",
        "outputId": "309cae15-b383-4c4c-8a69-665a46f74cbd"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings.txt', <http.client.HTTPMessage at 0x7fbfa34f2890>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eDRGo02FqEz9",
        "outputId": "4439e64c-e22b-456d-f4bc-2fe8079c12f2"
      },
      "source": [
        "naver_df = pd.read_table('ratings.txt')\n",
        "naver_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuNq2qiHqWK7",
        "outputId": "77c7bab1-1f83-4c5c-bca1-e41374312dce"
      },
      "source": [
        "naver_df = naver_df.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "print(naver_df.isnull().values.any()) # Null 값이 존재하는지 확인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6oyRgzuqG0O"
      },
      "source": [
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(naver_df['document']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUxat59Kr_HN"
      },
      "source": [
        "tokenizer = BertWordPieceTokenizer(lowercase=False, strip_accents=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGak2nRzz1VF"
      },
      "source": [
        "lowercase : True일 경우 토크나이저는 영어의 대문자와 소문자를 동일한 문자 취급.  \n",
        "strip_accents : True일 경우 악센트 제거.  \n",
        " ex) é → e, ô → o  \n",
        "wordpieces_prefix : 서브워드로 쪼개졌을 경우 뒤의 서브워드에는 ##를 부착하여 원래 단어에서 분리된 것임을 표시.  \n",
        "  ex) 안녕하세요 -> [안녕, ##하세요]  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqfckZaKsB52"
      },
      "source": [
        "data_file = 'naver_review.txt'\n",
        "vocab_size = 30000\n",
        "limit_alphabet = 6000\n",
        "min_frequency = 5\n",
        "\n",
        "tokenizer.train(files=data_file,\n",
        "                vocab_size=vocab_size,\n",
        "                limit_alphabet=limit_alphabet,\n",
        "                min_frequency=min_frequency,\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jub515LugVN"
      },
      "source": [
        "vocab_size : 단어 집합의 크기  \n",
        "limit_alphabet : merge가 되지 않은 초기 토큰(character 단위)의 허용 제한 개수  \n",
        "min_frequency : merge가 되기 위한 pair의 최소 등장 횟수\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roBgrAOpvvR0",
        "outputId": "5dbba5eb-1b79-4556-9ea4-ac0d2d353117"
      },
      "source": [
        "# vocab 저장\n",
        "tokenizer.save_model('./')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fJ9bM4_twOK1",
        "outputId": "322f8c38-6abb-443e-ec0a-6e2aec5223cd"
      },
      "source": [
        "# vocab 로드\n",
        "df = pd.read_fwf('vocab.txt', header=None)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[PAD]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[UNK]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[CLS]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[SEP]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MASK]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>말과</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>말들이</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>말라는</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>말밖에는</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>맘을</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "0       [PAD]\n",
              "1       [UNK]\n",
              "2       [CLS]\n",
              "3       [SEP]\n",
              "4      [MASK]\n",
              "...       ...\n",
              "29995      말과\n",
              "29996     말들이\n",
              "29997     말라는\n",
              "29998    말밖에는\n",
              "29999      맘을\n",
              "\n",
              "[30000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtXbcZHasGxO",
        "outputId": "52130d44-7ec6-4d07-e255-e5f8f9a4d42a"
      },
      "source": [
        "encoded = tokenizer.encode('아 배고픈데 짜장면먹고싶다')\n",
        "print('토큰화 결과 :',encoded.tokens)\n",
        "print('정수 인코딩 :',encoded.ids)\n",
        "print('디코딩 :',tokenizer.decode(encoded.ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화 결과 : ['아', '배고', '##픈', '##데', '짜장면', '##먹고', '##싶다']\n",
            "정수 인코딩 : [2111, 20629, 3979, 3244, 24682, 7871, 7379]\n",
            "디코딩 : 아 배고픈데 짜장면먹고싶다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYQwqZajsqKs",
        "outputId": "eae9b700-9d5e-4cef-f4e9-567944ac7f73"
      },
      "source": [
        "encoded = tokenizer.encode('커피 한잔의 여유를 즐기다')\n",
        "print('토큰화 결과 :',encoded.tokens)\n",
        "print('정수 인코딩 :',encoded.ids)\n",
        "print('디코딩 :',tokenizer.decode(encoded.ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화 결과 : ['커피', '한잔', '##의', '여유', '##를', '즐기', '##다']\n",
            "정수 인코딩 : [12825, 25641, 3435, 12696, 3419, 10784, 3260]\n",
            "디코딩 : 커피 한잔의 여유를 즐기다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 기타 토크나이저"
      ],
      "metadata": {
        "id": "gA4GhI1apI5r"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkgJ-USR4cg9",
        "outputId": "9dbfee4b-1c33-408d-f992-8dc2c3a8aed0"
      },
      "source": [
        "from tokenizers import ByteLevelBPETokenizer, CharBPETokenizer, SentencePieceBPETokenizer\n",
        "                            \n",
        "tokenizer = SentencePieceBPETokenizer()\n",
        "tokenizer.train('naver_review.txt', vocab_size=10000, min_frequency=5)\n",
        "\n",
        "encoded = tokenizer.encode(\"이 영화는 정말 재미있습니다.\")\n",
        "print(encoded.tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁이', '▁영화는', '▁정말', '▁재미있', '습니다.']\n"
          ]
        }
      ]
    }
  ]
}