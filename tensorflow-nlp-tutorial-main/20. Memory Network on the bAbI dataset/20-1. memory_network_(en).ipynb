{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memory network (en).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlviU4N-NAv1"
      },
      "source": [
        "2021년 10월 8일에 최종 테스트 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtP8ZuteNnXu"
      },
      "source": [
        "링크 : https://wikidocs.net/82475"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jJWHK_eANDN0",
        "outputId": "aa946e96-864e-4328-ad7a-eac9e105bfbd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs9zPMoeDZzb"
      },
      "source": [
        "# 메모리 네트워크를 이용한 영어 QA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVLCRblwDXEl"
      },
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ2N0w4iFRDX"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmBTrc8BDX9X",
        "outputId": "de87cdb3-f140-4559-b98f-3b1852c01475"
      },
      "source": [
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                'babi_tasks_1-20_v1-2.tar.gz')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11747328/11745123 [==============================] - 0s 0us/step\n",
            "11755520/11745123 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJj30yVoDYEG"
      },
      "source": [
        "with tarfile.open(path) as tar:\n",
        " tar.extractall()\n",
        " tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRxkEc8oFTjb"
      },
      "source": [
        "## Babi 데이터셋 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GciuOfrjDYMH",
        "outputId": "8eda1e0e-2515-45f9-b3c2-99aa9da82509"
      },
      "source": [
        "i = 0\n",
        "lines = open(TRAIN_FILE , \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "2 John went to the hallway.\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "4 Daniel went back to the hallway.\n",
            "5 Sandra moved to the garden.\n",
            "6 Where is Daniel? \thallway\t4\n",
            "7 John moved to the office.\n",
            "8 Sandra journeyed to the bathroom.\n",
            "9 Where is Daniel? \thallway\t4\n",
            "10 Mary moved to the hallway.\n",
            "11 Daniel travelled to the office.\n",
            "12 Where is Daniel? \toffice\t11\n",
            "13 John went back to the garden.\n",
            "14 John moved to the bedroom.\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "1 Sandra travelled to the office.\n",
            "2 Sandra went to the bathroom.\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "4 Mary went to the bedroom.\n",
            "5 Daniel moved to the hallway.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liYRP4mKFWVQ"
      },
      "source": [
        "## 스토리, 질문, 답변 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZ4hjTPDYPM"
      },
      "source": [
        "def read_data(dir):\n",
        "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
        "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
        "    lines = open(dir, \"rb\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.decode(\"utf-8\") # b' 제거\n",
        "        line = line.strip() # '\\n' 제거\n",
        "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "        # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "        if int(idx) == 1:\n",
        "            story_temp = []\n",
        "\n",
        "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
        "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "        else: # 현재 읽는 줄이 스토리인 경우\n",
        "            story_temp.append(text) # 임시 저장\n",
        "\n",
        "    lines.close()\n",
        "    return stories, questions, answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNAOOBbfDYJm"
      },
      "source": [
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNh7jAryDYHI"
      },
      "source": [
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAe5T7j5Dj0R",
        "outputId": "294b4702-8e4c-430d-8c71-bcd91bb95580"
      },
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH-whk9FDlF9",
        "outputId": "978bdf69-7af3-40c4-9d77-f9bf308a0d4b"
      },
      "source": [
        "train_stories[3576]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John went back to the garden.',\n",
              " 'Mary went to the kitchen.',\n",
              " 'Sandra went back to the bedroom.',\n",
              " 'John travelled to the bedroom.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fI9AfnQvDl07",
        "outputId": "e41e0f67-6fc4-4091-944a-573e7abcfe36"
      },
      "source": [
        "train_questions[3576]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Where is John? '"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c-gE6Y2CDm1W",
        "outputId": "6f2a8e07-1392-4c64-e556-cd77ec5dae1a"
      },
      "source": [
        "train_answers[3576]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bedroom'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-6z6RxyFez9"
      },
      "source": [
        "## 단어 집합 생성 및 토큰화 및 스토리와 질문의 최대 길이 구하기  \n",
        "단, 스토리는 모두 펼쳐서 하나의 샘플 처리."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE6GiR7DDokB"
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HykreiVoDp_Q"
      },
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFzvZx8PDrik"
      },
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss6DWK9IDtIr",
        "outputId": "075b4bbc-30a7-4045-ec3f-d3fd69974225"
      },
      "source": [
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbGiMRvuDu1k"
      },
      "source": [
        "vocab_size = len(word2idx) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7x14T1-DwC8",
        "outputId": "ba8315aa-bc61-4780-fd66-f8c99168e325"
      },
      "source": [
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스토리의 최대 길이 : 68\n",
            "질문의 최대 길이 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXGyRWzuF4Df"
      },
      "source": [
        "## 정수 인코딩 및 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zqvr2MADxOg"
      },
      "source": [
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
        "        # 정답은 원-핫 인코딩\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbKaunR_Dyjh"
      },
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUiYGluHD0s2",
        "outputId": "a4a6e5b7-358f-41bc-b420-367972089d4a"
      },
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aucZyNPSD2eM",
        "outputId": "52f3a35a-e4a9-4a2a-ca8f-496ea4400693"
      },
      "source": [
        "Xstrain[3576]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  6,  4, 11,  1,  2, 13,  3,  8,  4,\n",
              "        1,  2, 17,  3,  5,  4, 11,  1,  2, 18,  3,  6,  9,  1,  2, 18,  3],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XusaXO8LD6d8",
        "outputId": "e53a9dd3-faab-43d7-d54b-8ef5ced86a06"
      },
      "source": [
        "Xqtrain[3576]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 20,  6, 21], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVRkfkJwD-Kj",
        "outputId": "d8a305d0-5346-49c4-e455-54fba512e3a2"
      },
      "source": [
        "Ytrain[3576]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdj_11K2F6Rt"
      },
      "source": [
        "## 메모리 네트워크 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6XWVvzPEApv"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVBqicL_EB2f"
      },
      "source": [
        "# 에포크 횟수\n",
        "train_epochs = 120\n",
        "# 배치 크기\n",
        "batch_size = 32\n",
        "# 임베딩 크기\n",
        "embed_size = 50\n",
        "# LSTM의 크기\n",
        "lstm_size = 64\n",
        "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8saI92oEC86",
        "outputId": "3601d73c-c84b-427e-853a-3cecc458452a"
      },
      "source": [
        "# 플레이스 홀더. 입력을 담는 변수\n",
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 68), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\")\n",
            "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2gNvy-wEECC"
      },
      "source": [
        "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnNOXEPDEGJj"
      },
      "source": [
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukaymDiSEHcs",
        "outputId": "7614db8f-897a-4722-e1f3-e72e36a72821"
      },
      "source": [
        "# 실질적인 임베딩 과정\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 68, 50), dtype=tf.float32, name=None), name='sequential_3/dropout_4/Identity:0', description=\"created by layer 'sequential_3'\")\n",
            "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='sequential_4/dropout_5/Identity:0', description=\"created by layer 'sequential_4'\")\n",
            "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 4, 50), dtype=tf.float32, name=None), name='sequential_5/dropout_6/Identity:0', description=\"created by layer 'sequential_5'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh7Gcx9SEItb",
        "outputId": "fff54d50-3854-4dae-ba8c-12a9319c79d2"
      },
      "source": [
        "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
        "# 유사도는 내적을 사용한다.\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='activation_2/Softmax:0', description=\"created by layer 'activation_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSdoMHmrEMBR"
      },
      "source": [
        "# 유사도가 반영된 어텐션 분포 행렬과 임베딩 C를 거친 스토리 행렬을 더한다.\n",
        "# 두 행렬 모두 크기는 (68, 4)이다.\n",
        "# 이로부터 얻은 행렬은 어텐션 값 행렬(Attention Value Matrix)이다.\n",
        "response = add([match, input_encoded_c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtvioXUaENXL",
        "outputId": "d91c6c08-6f82-42c1-ba1d-158d4c122ec9"
      },
      "source": [
        "# 질문 행렬은 (4, 50)의 크기를 가진다.\n",
        "# 하지만 어텐션 값 행렬의 크기는 (68, 4)이다.\n",
        "# 이 두 개를 연결시켜주기 위해서 어텐션 값 행렬의 크기를 (4, 68)로 변환해준다.\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n",
        "\n",
        "# 질문 행렬과 어텐션 값 행렬을 연결한다.\n",
        "# (4, 118)의 크기를 가진다.\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 68), dtype=tf.float32, name=None), name='permute_1/transpose:0', description=\"created by layer 'permute_1'\")\n",
            "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 118), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ-WVFYOE3Hl"
      },
      "source": [
        "answer = LSTM(lstm_size)(answer)\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbRKnZa5E6A7",
        "outputId": "1703547d-8d32-426e-e8b7-f7657511c79f"
      },
      "source": [
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# start training the model\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, None, 50)     1100        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 4, 50)        1100        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 68, 4)        0           sequential_3[0][0]               \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 68, 4)        0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, None, 4)      88          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 68, 4)        0           activation_2[0][0]               \n",
            "                                                                 sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 4, 68)        0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 118)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           46848       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 22)           1430        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 22)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 5s 11ms/step - loss: 1.8877 - acc: 0.1724 - val_loss: 1.8049 - val_acc: 0.2210\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.7108 - acc: 0.2643 - val_loss: 1.6009 - val_acc: 0.3600\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5561 - acc: 0.3709 - val_loss: 1.4884 - val_acc: 0.4200\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5015 - acc: 0.4086 - val_loss: 1.4990 - val_acc: 0.3980\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4530 - acc: 0.4384 - val_loss: 1.3904 - val_acc: 0.4500\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3999 - acc: 0.4591 - val_loss: 1.3510 - val_acc: 0.4940\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3768 - acc: 0.4709 - val_loss: 1.3212 - val_acc: 0.5000\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3583 - acc: 0.4708 - val_loss: 1.3016 - val_acc: 0.5010\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3286 - acc: 0.4838 - val_loss: 1.2831 - val_acc: 0.5010\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3107 - acc: 0.4944 - val_loss: 1.2750 - val_acc: 0.5190\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.2940 - acc: 0.4998 - val_loss: 1.2568 - val_acc: 0.5230\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2707 - acc: 0.5049 - val_loss: 1.2204 - val_acc: 0.5290\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2595 - acc: 0.5093 - val_loss: 1.2194 - val_acc: 0.5270\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2229 - acc: 0.5138 - val_loss: 1.2206 - val_acc: 0.5070\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2118 - acc: 0.5155 - val_loss: 1.1828 - val_acc: 0.5170\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1873 - acc: 0.5152 - val_loss: 1.1586 - val_acc: 0.5250\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1781 - acc: 0.5151 - val_loss: 1.1730 - val_acc: 0.5050\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1672 - acc: 0.5186 - val_loss: 1.1529 - val_acc: 0.5170\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1517 - acc: 0.5211 - val_loss: 1.1529 - val_acc: 0.5150\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1461 - acc: 0.5247 - val_loss: 1.1443 - val_acc: 0.5150\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1428 - acc: 0.5265 - val_loss: 1.1519 - val_acc: 0.5200\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1316 - acc: 0.5323 - val_loss: 1.1497 - val_acc: 0.5210\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1291 - acc: 0.5267 - val_loss: 1.1438 - val_acc: 0.5190\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1164 - acc: 0.5321 - val_loss: 1.1535 - val_acc: 0.5060\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1101 - acc: 0.5319 - val_loss: 1.1574 - val_acc: 0.5190\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1042 - acc: 0.5400 - val_loss: 1.1579 - val_acc: 0.5170\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0969 - acc: 0.5353 - val_loss: 1.1397 - val_acc: 0.5190\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0861 - acc: 0.5417 - val_loss: 1.1555 - val_acc: 0.5040\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0839 - acc: 0.5424 - val_loss: 1.1599 - val_acc: 0.5180\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0757 - acc: 0.5442 - val_loss: 1.1604 - val_acc: 0.4990\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0690 - acc: 0.5504 - val_loss: 1.1512 - val_acc: 0.5200\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0629 - acc: 0.5496 - val_loss: 1.1493 - val_acc: 0.5070\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0475 - acc: 0.5583 - val_loss: 1.1461 - val_acc: 0.5220\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0388 - acc: 0.5643 - val_loss: 1.1278 - val_acc: 0.5230\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.0107 - acc: 0.5835 - val_loss: 1.1107 - val_acc: 0.5590\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9670 - acc: 0.6172 - val_loss: 1.0744 - val_acc: 0.5950\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8831 - acc: 0.6646 - val_loss: 0.9027 - val_acc: 0.6610\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7357 - acc: 0.7367 - val_loss: 0.6828 - val_acc: 0.7500\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6191 - acc: 0.7779 - val_loss: 0.6236 - val_acc: 0.7610\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5601 - acc: 0.7939 - val_loss: 0.5961 - val_acc: 0.7780\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4973 - acc: 0.8215 - val_loss: 0.5355 - val_acc: 0.7980\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4361 - acc: 0.8343 - val_loss: 0.4578 - val_acc: 0.8030\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3944 - acc: 0.8519 - val_loss: 0.4131 - val_acc: 0.8320\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3675 - acc: 0.8653 - val_loss: 0.3976 - val_acc: 0.8420\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3374 - acc: 0.8720 - val_loss: 0.4072 - val_acc: 0.8340\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3300 - acc: 0.8768 - val_loss: 0.3840 - val_acc: 0.8400\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3235 - acc: 0.8790 - val_loss: 0.3760 - val_acc: 0.8440\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3059 - acc: 0.8838 - val_loss: 0.3600 - val_acc: 0.8570\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2889 - acc: 0.8906 - val_loss: 0.3868 - val_acc: 0.8430\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2878 - acc: 0.8909 - val_loss: 0.3419 - val_acc: 0.8590\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2739 - acc: 0.8941 - val_loss: 0.3559 - val_acc: 0.8560\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2650 - acc: 0.9028 - val_loss: 0.3339 - val_acc: 0.8660\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2571 - acc: 0.9074 - val_loss: 0.3164 - val_acc: 0.8760\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2403 - acc: 0.9089 - val_loss: 0.3094 - val_acc: 0.8820\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2306 - acc: 0.9127 - val_loss: 0.3409 - val_acc: 0.8720\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2066 - acc: 0.9197 - val_loss: 0.2919 - val_acc: 0.8960\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2053 - acc: 0.9245 - val_loss: 0.2717 - val_acc: 0.8930\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1891 - acc: 0.9317 - val_loss: 0.2551 - val_acc: 0.9140\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1726 - acc: 0.9366 - val_loss: 0.2386 - val_acc: 0.9230\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1694 - acc: 0.9417 - val_loss: 0.2530 - val_acc: 0.9120\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1561 - acc: 0.9434 - val_loss: 0.2336 - val_acc: 0.9160\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1477 - acc: 0.9470 - val_loss: 0.2135 - val_acc: 0.9270\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1426 - acc: 0.9520 - val_loss: 0.2272 - val_acc: 0.9220\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1309 - acc: 0.9520 - val_loss: 0.2229 - val_acc: 0.9260\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1313 - acc: 0.9553 - val_loss: 0.1872 - val_acc: 0.9370\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1208 - acc: 0.9565 - val_loss: 0.2153 - val_acc: 0.9290\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1206 - acc: 0.9584 - val_loss: 0.1979 - val_acc: 0.9290\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1208 - acc: 0.9578 - val_loss: 0.1915 - val_acc: 0.9300\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1129 - acc: 0.9611 - val_loss: 0.1853 - val_acc: 0.9380\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0995 - acc: 0.9648 - val_loss: 0.1852 - val_acc: 0.9320\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0993 - acc: 0.9632 - val_loss: 0.1984 - val_acc: 0.9300\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0943 - acc: 0.9695 - val_loss: 0.2176 - val_acc: 0.9320\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0938 - acc: 0.9669 - val_loss: 0.1850 - val_acc: 0.9410\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0838 - acc: 0.9706 - val_loss: 0.2001 - val_acc: 0.9370\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0821 - acc: 0.9723 - val_loss: 0.1827 - val_acc: 0.9390\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0814 - acc: 0.9717 - val_loss: 0.2061 - val_acc: 0.9410\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0746 - acc: 0.9746 - val_loss: 0.2092 - val_acc: 0.9370\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0790 - acc: 0.9741 - val_loss: 0.2033 - val_acc: 0.9360\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0706 - acc: 0.9763 - val_loss: 0.1823 - val_acc: 0.9390\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0708 - acc: 0.9781 - val_loss: 0.1917 - val_acc: 0.9350\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0600 - acc: 0.9797 - val_loss: 0.2076 - val_acc: 0.9400\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0603 - acc: 0.9800 - val_loss: 0.2074 - val_acc: 0.9440\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0633 - acc: 0.9788 - val_loss: 0.1742 - val_acc: 0.9470\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0565 - acc: 0.9816 - val_loss: 0.1880 - val_acc: 0.9470\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0604 - acc: 0.9806 - val_loss: 0.1941 - val_acc: 0.9510\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0570 - acc: 0.9819 - val_loss: 0.1759 - val_acc: 0.9470\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0518 - acc: 0.9829 - val_loss: 0.1723 - val_acc: 0.9550\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0576 - acc: 0.9829 - val_loss: 0.1804 - val_acc: 0.9480\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0549 - acc: 0.9829 - val_loss: 0.1866 - val_acc: 0.9490\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0473 - acc: 0.9835 - val_loss: 0.1723 - val_acc: 0.9510\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0519 - acc: 0.9836 - val_loss: 0.1796 - val_acc: 0.9540\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0498 - acc: 0.9849 - val_loss: 0.1689 - val_acc: 0.9500\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0500 - acc: 0.9864 - val_loss: 0.1810 - val_acc: 0.9460\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0457 - acc: 0.9873 - val_loss: 0.1840 - val_acc: 0.9470\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0409 - acc: 0.9877 - val_loss: 0.1794 - val_acc: 0.9550\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0436 - acc: 0.9870 - val_loss: 0.1614 - val_acc: 0.9520\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0409 - acc: 0.9877 - val_loss: 0.1615 - val_acc: 0.9560\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0420 - acc: 0.9871 - val_loss: 0.1724 - val_acc: 0.9530\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0419 - acc: 0.9882 - val_loss: 0.1845 - val_acc: 0.9560\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0424 - acc: 0.9882 - val_loss: 0.1817 - val_acc: 0.9490\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0400 - acc: 0.9879 - val_loss: 0.1858 - val_acc: 0.9520\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0396 - acc: 0.9872 - val_loss: 0.1907 - val_acc: 0.9520\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0359 - acc: 0.9896 - val_loss: 0.1750 - val_acc: 0.9530\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0424 - acc: 0.9871 - val_loss: 0.2003 - val_acc: 0.9540\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0400 - acc: 0.9875 - val_loss: 0.1687 - val_acc: 0.9590\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0408 - acc: 0.9873 - val_loss: 0.2029 - val_acc: 0.9500\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0376 - acc: 0.9891 - val_loss: 0.1709 - val_acc: 0.9560\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0328 - acc: 0.9895 - val_loss: 0.2114 - val_acc: 0.9550\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0358 - acc: 0.9899 - val_loss: 0.1699 - val_acc: 0.9520\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0384 - acc: 0.9885 - val_loss: 0.2010 - val_acc: 0.9550\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0372 - acc: 0.9888 - val_loss: 0.1588 - val_acc: 0.9620\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0327 - acc: 0.9906 - val_loss: 0.2254 - val_acc: 0.9490\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0385 - acc: 0.9904 - val_loss: 0.1756 - val_acc: 0.9540\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0315 - acc: 0.9905 - val_loss: 0.1733 - val_acc: 0.9580\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0330 - acc: 0.9908 - val_loss: 0.2231 - val_acc: 0.9510\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0286 - acc: 0.9920 - val_loss: 0.1786 - val_acc: 0.9580\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0376 - acc: 0.9913 - val_loss: 0.1623 - val_acc: 0.9660\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0286 - acc: 0.9914 - val_loss: 0.2017 - val_acc: 0.9550\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0288 - acc: 0.9899 - val_loss: 0.1778 - val_acc: 0.9610\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0365 - acc: 0.9907 - val_loss: 0.1666 - val_acc: 0.9580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u8ZjzcRE9L1",
        "outputId": "31da59d0-5d2e-4d97-802b-12199478c4df"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1666 - acc: 0.9580\n",
            "\n",
            " 테스트 정확도: 0.9580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "1FAs5IVLE-t3",
        "outputId": "e6a00dcc-eb98-41c7-cfb9-66fe17acbf1d"
      },
      "source": [
        "# plot accuracy and loss plot\n",
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# labels\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}