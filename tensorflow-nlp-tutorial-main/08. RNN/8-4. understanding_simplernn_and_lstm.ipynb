{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding SimpleRNN and LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZj323-qzWPB"
      },
      "source": [
        "이 자료는 위키독스 딥 러닝을 이용한 자연어 처리 입문의 RNN과 LSTM 이해하기 튜토리얼입니다.  \n",
        "\n",
        "링크 : https://wikidocs.net/106473"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2wQr1RxQu41"
      },
      "source": [
        "# 1. 임의의 입력 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdNZAMg7QwkS"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tau6slmbQz0S"
      },
      "source": [
        "우선 RNN과 LSTM을 테스트하기 위한 임의의 입력을 만듭니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jrPqXecQzWZ",
        "outputId": "cddcfde8-0d3d-461a-8316-1785d8f1db54"
      },
      "source": [
        "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
        "print(np.shape(train_X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFdVp0wPQ2_k"
      },
      "source": [
        "위 입력은 단어 벡터의 차원은 5이고, 문장의 길이가 4인 경우를 가정한 입력입니다. 다시 말해 4번의 시점(timesteps)이 존재하고, 각 시점마다 5차원의 단어 벡터가 입력으로 사용됩니다. 그런데 앞서 RNN은 2D 텐서가 아니라 3D 텐서를 입력을 받는다고 언급한 바 있습니다. 즉, 위에서 만든 2D 텐서를 3D 텐서로 변경합니다. 이는 배치 크기 1을 추가해주므로서 해결합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfChXiztQ1YZ",
        "outputId": "6786a435-1627-4773-9148-ca3675b51812"
      },
      "source": [
        "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
        "train_X = np.array(train_X, dtype=np.float32)\n",
        "print(train_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 4, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCT0bOUOQ5ed"
      },
      "source": [
        "(batch_size, timesteps, input_dim)에 해당되는 (1, 4, 5)의 크기를 가지는 3D 텐서가 생성되었습니다. batch_size는 한 번에 RNN이 학습하는 데이터의 양을 의미하지만, 여기서는 샘플이 1개 밖에 없으므로 batch_size는 1입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1MZlFpmQ7E3"
      },
      "source": [
        "# 2. Simple RNN 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4w_lF9MQ_o_"
      },
      "source": [
        "위에서 생성한 데이터를 SimpleRNN의 입력으로 사용하여 SimpleRNN의 출력값을 이해해보겠습니다. SimpleRNN에는 여러 인자가 있으며 대표적인 인자로 return_sequences와 return_state가 있습니다. 기본값으로는 둘 다 False로 지정되어져 있으므로 별도 지정을 하지 않을 경우에는 False로 처리됩니다. 우선, 은닉 상태의 크기를 3으로 지정하고, 두 인자 값이 모두 False일 때의 출력값을 보겠습니다.\n",
        "\n",
        "앞으로의 실습에서 SimpleRNN을 매번 재선언하므로 은닉 상태의 값 자체는 매번 초기화되어 이전 출력과 값의 일관성은 없습니다. 그래서 출력값 자체보다는 해당 값의 크기(shape)에 주목해야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upaj2EzDQ9v-",
        "outputId": "95d9fb71-be75-47ba-caa9-b41f3f170a53"
      },
      "source": [
        "rnn = SimpleRNN(3)\n",
        "# rnn = SimpleRNN(3, return_sequences=False, return_state=False)와 동일.\n",
        "hidden_state = rnn(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden state : [[-0.6206769  -0.96079373 -0.94467103]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoPeBk5BRCSQ"
      },
      "source": [
        "(1, 3) 크기의 텐서가 출력되는데, 이는 마지막 시점의 은닉 상태입니다. 은닉 상태의 크기를 3으로 지정했음을 주목합시다. 기본적으로 return_sequences가 False인 경우에는 SimpleRNN은 마지막 시점의 은닉 상태만 출력합니다. 이번에는 return_sequences를 True로 지정하여 모든 시점의 은닉 상태를 출력해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcd93uq8RBCK",
        "outputId": "97eceb65-c34e-481d-df5d-c132a4b41a6f"
      },
      "source": [
        "rnn = SimpleRNN(3, return_sequences=True)\n",
        "hidden_states = rnn(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden states : [[[-0.7406934   0.96721464  0.9941826 ]\n",
            "  [ 0.15434016  0.99763674  0.99873525]\n",
            "  [ 0.6581547   0.99725753  0.9717172 ]\n",
            "  [-0.91555536  0.9496525   0.787466  ]]], shape: (1, 4, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz03GZ1nRF-G"
      },
      "source": [
        "(1, 4, 3) 크기의 텐서가 출력됩니다. 앞서 입력 데이터는 (1, 4, 5)의 크기를 가지는 3D 텐서였고, 그 중 4가 시점(timesteps)에 해당하는 값이므로 모든 시점에 대해서 은닉 상태의 값을 출력하여 (1, 4, 3) 크기의 텐서를 출력하는 것입니다.\n",
        "\n",
        "return_state가 True일 경우에는 return_sequences의 True/False 여부와 상관없이 마지막 시점의 은닉 상태를 출력합니다. 가령, return_sequences가 True이면서, return_state를 True로 할 경우 SimpleRNN은 두 개의 출력을 리턴합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMSoAKq_RD8Z",
        "outputId": "78500f75-57bc-47ec-bbbc-7a2c5f753b09"
      },
      "source": [
        "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
        "hidden_states, last_state = rnn(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden states : [[[-0.99524516  0.7450907  -0.9913399 ]\n",
            "  [-0.9992803   0.96811783 -0.99907535]\n",
            "  [-0.9950502   0.99522436 -0.86860895]\n",
            "  [-0.9904826   0.94040406 -0.99399334]]], shape: (1, 4, 3)\n",
            "last hidden state : [[-0.9904826   0.94040406 -0.99399334]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn5X3pbHRJKq"
      },
      "source": [
        "첫번째 출력은 return_sequences=True로 인한 출력으로 모든 시점의 은닉 상태입니다. 두번째 출력은 return_state=True로 인한 출력으로 마지막 시점의 은닉 상태입니다. 실제로 출력을 보면 모든 시점의 은닉 상태인 (1, 4, 3) 텐서의 마지막 벡터값이 return_state=True로 인해 출력된 벡터값과 일치하는 것을 볼 수 있습니다. (둘 다 [-0.5144398 -0.5037417 0.96605766])\n",
        "\n",
        "그렇다면 return_sequences는 False인데, retun_state가 True인 경우는 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV8Pjr5YRHlR",
        "outputId": "c1f7704e-8ffa-4718-b744-ff2c46530658"
      },
      "source": [
        "rnn = SimpleRNN(3, return_sequences=False, return_state=True)\n",
        "hidden_state, last_state = rnn(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden state : [[-0.03425771 -0.9931918   0.99198115]], shape: (1, 3)\n",
            "last hidden state : [[-0.03425771 -0.9931918   0.99198115]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2niDehoRL2X"
      },
      "source": [
        "두 개의 출력 모두 마지막 시점의 은닉 상태를 출력하게 됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQv1roK3YqUx",
        "outputId": "32920fa9-f0a2-4b85-a63a-6be17ffa4a67"
      },
      "source": [
        "    gru = GRU(3, return_sequences=True, return_state=True)\n",
        "    output, state = gru(train_X)\n",
        "\n",
        "    print(output)\n",
        "    print(state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.23608883 -0.03089973 -0.00853387]\n",
            "  [-0.6869065  -0.26680383 -0.02222079]\n",
            "  [-0.8169483  -0.17411529 -0.03034596]\n",
            "  [-0.85683155 -0.5692008   0.01336882]]], shape=(1, 4, 3), dtype=float32)\n",
            "tf.Tensor([[-0.85683155 -0.5692008   0.01336882]], shape=(1, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-5Bg2awRNHt"
      },
      "source": [
        "#3. LSTM 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8137afuMRQA0"
      },
      "source": [
        "사실 실제로 SimpleRNN이 사용되는 경우는 거의 없습니다. 이보다는 LSTM이나 GRU을 주로 사용하는데, 이번에는 임의의 입력에 대해서 LSTM을 사용할 경우를 보겠습니다. 우선 return_sequences를 False로 두고, return_state가 True인 경우를 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYqMntnkROif",
        "outputId": "d29bab8a-1ef2-4e23-c4bd-533eb1eade31"
      },
      "source": [
        "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
        "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden state : [[ 0.47742635 -0.1066403  -0.5185163 ]], shape: (1, 3)\n",
            "last hidden state : [[ 0.47742635 -0.1066403  -0.5185163 ]], shape: (1, 3)\n",
            "last cell state : [[ 1.4659885  -0.23560345 -0.9712877 ]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmrJI4wIRS2x"
      },
      "source": [
        "이번에는 SimpleRNN 때와는 달리, 세 개의 결과를 반환합니다. return_sequences가 False이므로 우선 첫번째 결과는 마지막 시점의 은닉 상태입니다. 그런데 LSTM이 SimpleRNN과 다른 점은 return_state를 True로 둔 경우에는 마지막 시점의 은닉 상태뿐만 아니라 셀 상태까지 반환한다는 점입니다. 이번에는 return_sequences를 True로 바꿔보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoGMv1-bRRXK",
        "outputId": "6624429c-7402-442d-e2d2-eb6dbfccc2c1"
      },
      "source": [
        "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
        "hidden_states, last_hidden_state, last_cell_state = lstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('last hidden state : {}, shape: {}'.format(last_hidden_state, last_hidden_state.shape))\n",
        "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden states : [[[ 0.0785605   0.38516212 -0.0678108 ]\n",
            "  [ 0.1069876   0.65910167 -0.1455892 ]\n",
            "  [ 0.0990002   0.38818565 -0.15435939]\n",
            "  [ 0.10057631  0.6606849  -0.11166821]]], shape: (1, 4, 3)\n",
            "last hidden state : [[ 0.10057631  0.6606849  -0.11166821]], shape: (1, 3)\n",
            "last cell state : [[ 0.41105613  1.4055569  -0.2592079 ]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgYoB-ubRVso"
      },
      "source": [
        "return_state가 True이므로 두번째 출력값이 마지막 은닉 상태, 세번째 출력값이 마지막 셀 상태인 것은 변함없지만 return_sequences가 True이므로 첫번째 출력값은 모든 시점의 은닉 상태가 출력됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cCnVY8dRXCb"
      },
      "source": [
        "# 4. BiLSTM 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDx4fNGCRb8A"
      },
      "source": [
        "난이도를 조금 올려서 양방향 LSTM의 출력값을 확인해보겠습니다. return_sequences가 True인 경우와 False인 경우에 대해서 은닉 상태의 값이 어떻게 바뀌는지 직접 비교하기 위해서 이번에는 출력되는 은닉 상태의 값을 고정시켜주겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf2va1XxRUCZ"
      },
      "source": [
        "k_init = tf.keras.initializers.Constant(value=0.1)\n",
        "b_init = tf.keras.initializers.Constant(value=0)\n",
        "r_init = tf.keras.initializers.Constant(value=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps3TKw0qReqN"
      },
      "source": [
        "우선 return_sequences가 False이고, return_state가 True인 경우입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bgHCC-ARdTi",
        "outputId": "44edad01-f2fb-46a5-cd18-a14ee79552fc"
      },
      "source": [
        "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
        "\n",
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden states : [[0.6303139  0.6303139  0.6303139  0.70387346 0.70387346 0.70387346]], shape: (1, 6)\n",
            "forward state : [[0.6303139 0.6303139 0.6303139]], shape: (1, 3)\n",
            "backward state : [[0.70387346 0.70387346 0.70387346]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRTpMvUkRhjM"
      },
      "source": [
        "이번에는 무려 5개의 값을 반환합니다. return_state가 True인 경우에는 정방향 LSTM의 은닉 상태와 셀 상태, 역방향 LSTM의 은닉 상태와 셀 상태 4가지를 반환하기 때문입니다. 다만, 셀 상태는 각각 forward_c와 backward_c에 저장만 하고 출력하지 않았습니다. 첫번째 출력값의 크기가 (1, 6)인 것에 주목합시다. 이는 return_sequences가 False인 경우 정방향 LSTM의 마지막 시점의 은닉 상태와 역방향 LSTM의 첫번째 시점의 은닉 상태가 연결된 채 반환되기 때문입니다. 그림으로 표현하면 아래와 같이 연결되어 다음층에서 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGZUL5j_JfpG"
      },
      "source": [
        "https://wikidocs.net/images/page/94748/bilstm3.PNG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS6yhj68SBoa"
      },
      "source": [
        "마찬가지로 return_state가 True인 경우에 반환한 은닉 상태의 값인 forward_h와 backward_h는 각각 정방향 LSTM의 마지막 시점의 은닉 상태와 역방향 LSTM의 첫번째 시점의 은닉 상태값입니다. 그리고 이 두 값을 연결한 값이 hidden_states에 출력되는 값입니다.\n",
        "\n",
        "이를 이용한 실습은 11챕터의 BiLSTM으로 한국어 스팀 리뷰 분류하기(https://wikidocs.net/94748)에 준비되어져 있습니다.\n",
        "\n",
        "정방향 LSTM의 마지막 시점의 은닉 상태값과 역방향 LSTM의 첫번째 은닉 상태값을 기억해둡시다.\n",
        "\n",
        "* 정방향 LSTM의 마지막 시점의 은닉 상태값 : [0.6303139 0.6303139 0.6303139]\n",
        "* 역방향 LSTM의 첫번째 시점의 은닉 상태값 : [0.70387346 0.70387346 0.70387346]  \n",
        "\n",
        "현재 은닉 상태의 값을 고정시켜두었기 때문에 return_sequences를 True로 할 경우, 출력이 어떻게 바뀌는지 비교가 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOXzDB10R_A6"
      },
      "source": [
        "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, \\\n",
        "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
        "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q39E4rwkSINp",
        "outputId": "8352ed75-c7ea-4b4c-c559-146b1254e92d"
      },
      "source": [
        "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
        "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
        "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden states : [[[0.35906476 0.35906476 0.35906476 0.70387346 0.70387346 0.70387346]\n",
            "  [0.5511133  0.5511133  0.5511133  0.5886358  0.5886358  0.5886358 ]\n",
            "  [0.5911575  0.5911575  0.5911575  0.39516988 0.39516988 0.39516988]\n",
            "  [0.6303139  0.6303139  0.6303139  0.2194224  0.2194224  0.2194224 ]]], shape: (1, 4, 6)\n",
            "forward state : [[0.6303139 0.6303139 0.6303139]], shape: (1, 3)\n",
            "backward state : [[0.70387346 0.70387346 0.70387346]], shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqCL3txBSMY1"
      },
      "source": [
        "hidden states의 출력값에서는 이제 모든 시점의 은닉 상태가 출력됩니다. 역방향 LSTM의 첫번째 시점의 은닉 상태는 더 이상 정방향 LSTM의 마지막 시점의 은닉 상태와 연결되는 것이 아니라 정방향 LSTM의 첫번째 시점의 은닉 상태와 연결됩니다.\n",
        "\n",
        "그림으로 표현하면 다음과 같이 연결되어 다음층의 입력으로 사용됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhqiEgYAJk0H"
      },
      "source": [
        "https://wikidocs.net/images/page/94748/bilstm1.PNG"
      ]
    }
  ]
}